{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "headers = {'User-Agent': 'Mozilla/3.0 (Win95; U)'}\n",
    "raw_html = requests.get('https://old.reddit.com', headers=headers)\n",
    "soup_doc = BeautifulSoup(raw_html.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "entries = soup_doc.find_all(class_ = 'thing')\n",
    "frontpage_posts = []\n",
    "for entry in entries:\n",
    "    try:\n",
    "        post = {}\n",
    "        post['title'] = entry.find('a', class_ = 'title').text\n",
    "        post['author'] = entry.find(class_ = 'author').text\n",
    "        post['author_profile'] = entry.find(class_ = 'author')['href']\n",
    "        post['content_link'] = entry.find('a', class_ = 'title', href = True)['href']\n",
    "        post['subreddit'] = entry.find(class_ = 'subreddit').text\n",
    "        post['subreddit_link'] = entry.find(class_ = 'subreddit')['href']\n",
    "        post['votes'] = entry.find(class_ = 'score unvoted')['title']\n",
    "        post['comment_count'] = entry.find(class_ = 'comments').text.split()[0]\n",
    "        post['comment_link'] = entry.find(class_ = 'comments')['href']\n",
    "        post['time'] = entry.find(class_ = 'live-timestamp')['datetime']\n",
    "        post['flair'] = ','. join([n.text for n in entry.find_all(class_ = \"linkflairlabel\")])\n",
    "        raw_html_comm = requests.get(post['comment_link'], headers=headers)\n",
    "        post['most_pop_comm'] = BeautifulSoup(raw_html_comm.content, \"html.parser\").find_all('form', class_ = 'usertext')[1].text\n",
    "        frontpage_posts.append(post)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_now = datetime.datetime.now()\n",
    "now = right_now.strftime(\"%Y-%m-%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(frontpage_posts)\n",
    "df.to_csv('./reddit/reddit-frontpage_'+now+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
