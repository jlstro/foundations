{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import statistics\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_now = datetime.datetime.now()\n",
    "today = right_now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.darksky.net/forecast/'\n",
    "api_key = 'XXXX'\n",
    "place = {'lat': '40.811623', 'long' : '-73.962852'} #Riverside Church Harlem\n",
    "options = ['?units=si']\n",
    "place_url = url+api_key+\"/\"+place['lat']+\",\"+place['long']+options[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_data = requests.get(place_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = str(place_data['currently']['temperature'])\n",
    "summ = str(place_data['currently']['summary'])\n",
    "feels = str(place_data['daily']['data'][0]['apparentTemperatureHigh'])\n",
    "hi_temp = str(place_data['daily']['data'][0]['temperatureHigh'])\n",
    "lo_temp = str(place_data['daily']['data'][0]['temperatureLow'])\n",
    "preciptype = str(place_data['daily']['data'][0]['precipType'])\n",
    "precipprop = str(round(place_data['daily']['data'][0]['precipProbability']*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_weather = (\"Right now it is \" + temp + \" degrees outside and \" + summ + \" - Today's high will be feeling like \" + feels + \" degrees, with an actual maximum of \" + hi_temp + \" degrees and a low of \" + lo_temp + \" There is a \" + precipprop + \" percent possibility of \" + preciptype + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_currency = bs(requests.get('https://www.xe.com/currencyconverter/convert/?Amount=1&From=EUR&To=USD').content, 'html.parser')\n",
    "exchange_rate = soup_doc_currency.find(class_ = 'uccResultUnit').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_nyt = bs(requests.get('https://www.nytimes.com').content, 'html.parser')\n",
    "nyt_top = soup_doc_nyt.find_all(class_ = 'story')\n",
    "list_of_stories = []\n",
    "for story in nyt_top:\n",
    "    story_dict = {}\n",
    "    try:\n",
    "        headline = story.find(class_ = 'story-heading')\n",
    "        byline = story.find(class_ = 'byline')\n",
    "        url  = story.find('a', href=True)['href']\n",
    "        story_dict['headline'] = headline.text\n",
    "        if byline:\n",
    "            story_dict['byline'] = byline.text\n",
    "        else:\n",
    "            story_dict['byline'] = '(no byline)'\n",
    "        if url:\n",
    "            story_dict['url'] = url\n",
    "        else:    \n",
    "            story_dict['url'] = 'no direct link.\\nGo to https://www.nytimes.com/'\n",
    "        list_of_stories.append(story_dict)\n",
    "    except:\n",
    "        pass\n",
    "nyt_stories = str(list_of_stories[0]['headline'] + '\\n' + list_of_stories[0]['byline'] + '\\n' + list_of_stories[0]['url'] + '\\n\\n' + list_of_stories[1]['headline'] + '\\n' + list_of_stories[1]['byline'] + '\\n' + list_of_stories[1]['url'] + '\\n\\n' + list_of_stories[2]['headline'] + '\\n' + list_of_stories[2]['byline'] + '\\n' + list_of_stories[2]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_nytger = bs(requests.get('https://www.nytimes.com/search?query=germany').content, 'html.parser')\n",
    "nyt_ger_title = soup_doc_nytger.find_all('li')[1].find('h4').text\n",
    "nyt_ger_shorturl = soup_doc_nytger.find_all('li')[1].find('a')['href']\n",
    "nyt_ger_url = 'https://www.nytimes.com/' + nyt_ger_shorturl\n",
    "nyt_ger = nyt_ger_title + '\\n' + nyt_ger_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These events are coming up in Harlem:\n",
      "\n",
      "AFRO FUSION CARDIO\n",
      "June 5 - 6:30 pm - July 17 - 6:30 pm \n",
      "http://experienceharlem.com/event/afro-fusion-cardio-3/\n",
      "\n",
      "HARLEM TEEN SHAKESPEARE INTENSIVE\n",
      "July 9 - 3:00 am - August 17 - 6:00 pm \n",
      "http://experienceharlem.com/event/harlem-teen-shakespeare-intensive-3/\n",
      "\n",
      "QUEENIE: Selected artworks by female artists from  El Museo del Barrioâ€™s Collection\n",
      "April 30 - 12:00 pm - June 23 - 5:00 pm \n",
      "http://experienceharlem.com/event/queenie-selected-artworks-by-female-artists-from-el-museo-del-barrios-collection/\n"
     ]
    }
   ],
   "source": [
    "soup_doc_harlem = bs(requests.get('http://experienceharlem.com/events/category/event/').content, 'html.parser')\n",
    "harlem_events = soup_doc_harlem.find_all(class_ = 'vevent')\n",
    "list_of_events = []\n",
    "for ev in harlem_events:\n",
    "    try:\n",
    "        ev_dict = {}\n",
    "        ev_dict['title'] = ev.find(class_ = 'entry-title').text.replace('\\n', '').replace('\\t', '') \n",
    "        ev_dict['date'] = ev.find(class_ = 'time-details').text \n",
    "        ev_dict['more'] = ev.find(class_ = \"tribe-events-read-more\")['href'] \n",
    "        list_of_events.append(ev_dict)\n",
    "    except:\n",
    "        pass\n",
    "upcoming_events = \"These events are coming up in Harlem:\\n\\n\" + list_of_events[0]['title'] + list_of_events[0]['date'] + '\\n' + list_of_events[0]['more'] + '\\n\\n' + list_of_events[1]['title'] + list_of_events[1]['date'] + '\\n' + list_of_events[1]['more'] + '\\n\\n' + list_of_events[2]['title'] + list_of_events[2]['date'] + '\\n' + list_of_events[2]['more'] \n",
    "#print(upcoming_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_body = todays_weather + \"\\n\\nThe latest exchange rate is: \" + exchange_rate +\"\\n\\nHere are the top stories from the nytimes.com homepage right now:\\n\\n\" + nyt_stories+ \"\\n\\nAnd here is their latest story on Germany:\\n\\n\" + nyt_ger + '\\n\\n' + upcoming_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"id\": \"<20180620121210.1.F4B31BCA612CAAE7@sandboxXXXX.mailgun.org>\",\\n  \"message\": \"Queued. Thank you.\"\\n}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_name = 'sandboxXXX.mailgun.org'\n",
    "response = requests.post(\"https://api.mailgun.net/v3/\" + domain_name + \"/messages\", \n",
    "                         auth=(\"api\", \"XXX\"),\n",
    "                         data={\"from\": \"WeatherBot <mailgun@sandboxXXX.mailgun.org>\",\n",
    "                               \"to\": [\"XXX+mailgun@gmail.com\"],\n",
    "                               \"subject\": \"Morning briefing for Jan, \" + today,\n",
    "                               \"text\": email_body}) \n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
